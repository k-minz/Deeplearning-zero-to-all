{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2], [2,3], [3,1], [4,3], [5,3], [6,2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hypothesis using sigmoid & Loss function & GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y)* tf.log(1 - hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "#train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy computation\n",
    "<pre>\n",
    "True : P(hypothesis) > 0.5\n",
    "False : else\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.763943\n",
      "200 0.67819023\n",
      "400 0.59755546\n",
      "600 0.55329216\n",
      "800 0.52337116\n",
      "1000 0.49996033\n",
      "1200 0.4799501\n",
      "1400 0.46197763\n",
      "1600 0.44539556\n",
      "1800 0.42987478\n",
      "2000 0.41523573\n",
      "2200 0.40137252\n",
      "2400 0.38821605\n",
      "2600 0.37571678\n",
      "2800 0.36383462\n",
      "3000 0.3525354\n",
      "3200 0.34178796\n",
      "3400 0.331563\n",
      "3600 0.32183275\n",
      "3800 0.31257063\n",
      "4000 0.30375087\n",
      "4200 0.29534945\n",
      "4400 0.287343\n",
      "4600 0.2797093\n",
      "4800 0.27242747\n",
      "5000 0.26547763\n",
      "5200 0.2588409\n",
      "5400 0.25249958\n",
      "5600 0.24643694\n",
      "5800 0.24063732\n",
      "6000 0.2350859\n",
      "6200 0.22976889\n",
      "6400 0.22467323\n",
      "6600 0.21978678\n",
      "6800 0.21509801\n",
      "7000 0.21059626\n",
      "7200 0.20627147\n",
      "7400 0.20211421\n",
      "7600 0.19811563\n",
      "7800 0.1942674\n",
      "8000 0.19056171\n",
      "8200 0.18699147\n",
      "8400 0.18354964\n",
      "8600 0.1802299\n",
      "8800 0.17702608\n",
      "9000 0.17393263\n",
      "9200 0.17094427\n",
      "9400 0.16805577\n",
      "9600 0.16526249\n",
      "9800 0.16256009\n",
      "10000 0.15994427\n",
      "\n",
      "hypothesis:  [[0.03525481]\n",
      " [0.16454802]\n",
      " [0.32578757]\n",
      " [0.7719811 ]\n",
      " [0.93349653]\n",
      " [0.9781507 ]] \n",
      "Correct [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "            \n",
    "#Accuracy            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                      feed_dict={X: x_data, Y:y_data})\n",
    "    print(\"\\nhypothesis: \",h ,\"\\nCorrect\", c,\"\\nAccuracy\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression_diabetes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"C:/Users/snuist/Desktop/Git/study/deeplearning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 9)\n"
     ]
    }
   ],
   "source": [
    "print(xy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. set X,Y,W,b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 8])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.cost / loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1-Y)*(1 - hypothesis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.5358485\n",
      "400 0.16493897\n",
      "800 0.04693743\n",
      "1200 0.02138246\n",
      "1600 0.011329445\n",
      "2000 0.0061302762\n",
      "2400 0.0029888458\n",
      "2800 0.0008878693\n",
      "3200 -0.0006230346\n",
      "3600 -0.0017714282\n",
      "4000 -0.0026836945\n",
      "4400 -0.0034352723\n",
      "4800 -0.0040737814\n",
      "5200 -0.004630671\n",
      "5600 -0.0051275794\n",
      "6000 -0.0055797365\n",
      "6400 -0.0059983865\n",
      "6800 -0.0063917064\n",
      "7200 -0.0067660874\n",
      "7600 -0.0071263867\n",
      "8000 -0.0074765156\n",
      "8400 -0.007819472\n",
      "8800 -0.008157782\n",
      "9200 -0.008493514\n",
      "9600 -0.008828301\n",
      "10000 -0.009163522\n",
      "\n",
      "hypothesis:  [[0.91701204]\n",
      " [0.99400604]\n",
      " [0.8177802 ]\n",
      " [0.9958438 ]\n",
      " [0.3631747 ]\n",
      " [0.9685469 ]\n",
      " [0.9917116 ]\n",
      " [0.91438735]\n",
      " [0.96058935]\n",
      " [0.8911625 ]\n",
      " [0.9403628 ]\n",
      " [0.6536948 ]\n",
      " [0.59130716]\n",
      " [0.98523176]\n",
      " [0.9493822 ]\n",
      " [0.7252261 ]\n",
      " [0.9483175 ]\n",
      " [0.99050444]\n",
      " [0.9766808 ]\n",
      " [0.88417083]\n",
      " [0.91398555]\n",
      " [0.6439138 ]\n",
      " [0.9310129 ]\n",
      " [0.939133  ]\n",
      " [0.87470716]\n",
      " [0.99337316]\n",
      " [0.9136734 ]\n",
      " [0.92464614]\n",
      " [0.96983284]\n",
      " [0.89307004]\n",
      " [0.9947314 ]\n",
      " [0.9700448 ]\n",
      " [0.9166311 ]\n",
      " [0.967096  ]\n",
      " [0.77933025]\n",
      " [0.907751  ]\n",
      " [0.97365236]\n",
      " [0.8369482 ]\n",
      " [0.9522412 ]\n",
      " [0.7691357 ]\n",
      " [0.981265  ]\n",
      " [0.5519684 ]\n",
      " [0.92512786]\n",
      " [0.2397363 ]\n",
      " [0.9670994 ]\n",
      " [0.98965013]\n",
      " [0.9530036 ]\n",
      " [0.9458825 ]\n",
      " [0.9924656 ]\n",
      " [0.99436754]\n",
      " [0.9878763 ]\n",
      " [0.8202187 ]\n",
      " [0.85663426]\n",
      " [0.9987789 ]\n",
      " [0.8591469 ]\n",
      " [0.5157665 ]\n",
      " [0.30826727]\n",
      " [0.91467494]\n",
      " [0.98855025]\n",
      " [0.90794045]\n",
      " [0.9859606 ]\n",
      " [0.9683248 ]\n",
      " [0.950073  ]\n",
      " [0.9842786 ]\n",
      " [0.86425817]\n",
      " [0.9008744 ]\n",
      " [0.99584913]\n",
      " [0.9608146 ]\n",
      " [0.97429425]\n",
      " [0.95375574]\n",
      " [0.5236559 ]\n",
      " [0.9642535 ]\n",
      " [0.9894684 ]\n",
      " [0.9970606 ]\n",
      " [0.9626547 ]\n",
      " [0.9657797 ]\n",
      " [0.857851  ]\n",
      " [0.9916065 ]\n",
      " [0.99641585]\n",
      " [0.98968935]\n",
      " [0.9485458 ]\n",
      " [0.9743807 ]\n",
      " [0.7882596 ]\n",
      " [0.9665737 ]\n",
      " [0.8358568 ]\n",
      " [0.9815377 ]\n",
      " [0.7782609 ]\n",
      " [0.9946143 ]\n",
      " [0.9963535 ]\n",
      " [0.97219634]\n",
      " [0.92722464]\n",
      " [0.97657317]\n",
      " [0.972226  ]\n",
      " [0.95253944]\n",
      " [0.99285746]\n",
      " [0.997626  ]\n",
      " [0.98090035]\n",
      " [0.90662396]\n",
      " [0.80086803]\n",
      " [0.9801129 ]\n",
      " [0.9214993 ]\n",
      " [0.9942291 ]\n",
      " [0.94426715]\n",
      " [0.9825371 ]\n",
      " [0.97307384]\n",
      " [0.9767329 ]\n",
      " [0.98558354]\n",
      " [0.9281133 ]\n",
      " [0.94756806]\n",
      " [0.921773  ]\n",
      " [0.98807377]\n",
      " [0.9759596 ]\n",
      " [0.9197484 ]\n",
      " [0.91574514]\n",
      " [0.9511037 ]\n",
      " [0.9675176 ]\n",
      " [0.98686904]\n",
      " [0.992512  ]\n",
      " [0.36259338]\n",
      " [0.9616474 ]\n",
      " [0.97603196]\n",
      " [0.9705748 ]\n",
      " [0.8982162 ]\n",
      " [0.9744392 ]\n",
      " [0.95189697]\n",
      " [0.9843908 ]\n",
      " [0.97820014]\n",
      " [0.8959361 ]\n",
      " [0.9637707 ]\n",
      " [0.7731619 ]\n",
      " [0.9424224 ]\n",
      " [0.9486015 ]\n",
      " [0.99099606]\n",
      " [0.9899978 ]\n",
      " [0.9477002 ]\n",
      " [0.95752484]\n",
      " [0.80043525]\n",
      " [0.97387403]\n",
      " [0.9814678 ]\n",
      " [0.96154225]\n",
      " [0.98807704]\n",
      " [0.92074484]\n",
      " [0.9627334 ]\n",
      " [0.9502563 ]\n",
      " [0.9750899 ]\n",
      " [0.92976826]\n",
      " [0.9471799 ]\n",
      " [0.9952461 ]\n",
      " [0.9441932 ]\n",
      " [0.9771194 ]\n",
      " [0.61561936]\n",
      " [0.8979584 ]\n",
      " [0.70585203]\n",
      " [0.73943996]\n",
      " [0.9939995 ]\n",
      " [0.9862453 ]\n",
      " [0.9912709 ]\n",
      " [0.27866125]\n",
      " [0.9432127 ]\n",
      " [0.94968873]\n",
      " [0.8914048 ]\n",
      " [0.9930647 ]\n",
      " [0.75880146]\n",
      " [0.96249104]\n",
      " [0.97489107]\n",
      " [0.9411858 ]\n",
      " [0.9589153 ]\n",
      " [0.9775918 ]\n",
      " [0.95770556]\n",
      " [0.9310683 ]\n",
      " [0.98704475]\n",
      " [0.9663685 ]\n",
      " [0.9924953 ]\n",
      " [0.7214253 ]\n",
      " [0.9608245 ]\n",
      " [0.37420496]\n",
      " [0.90223914]\n",
      " [0.791824  ]\n",
      " [0.9791531 ]\n",
      " [0.905192  ]\n",
      " [0.9934227 ]\n",
      " [0.9845942 ]\n",
      " [0.9612627 ]\n",
      " [0.80388814]\n",
      " [0.8741344 ]\n",
      " [0.8283938 ]\n",
      " [0.9052685 ]\n",
      " [0.93190074]\n",
      " [0.99031234]\n",
      " [0.89067996]\n",
      " [0.8950307 ]\n",
      " [0.62567586]\n",
      " [0.9918195 ]\n",
      " [0.8501396 ]\n",
      " [0.9935369 ]\n",
      " [0.98665166]\n",
      " [0.9124859 ]\n",
      " [0.97820264]\n",
      " [0.9267764 ]\n",
      " [0.94910127]\n",
      " [0.94494855]\n",
      " [0.99452037]\n",
      " [0.96556914]\n",
      " [0.9792939 ]\n",
      " [0.7754263 ]\n",
      " [0.8662166 ]\n",
      " [0.99241793]\n",
      " [0.8447285 ]\n",
      " [0.994826  ]\n",
      " [0.68366367]\n",
      " [0.8972774 ]\n",
      " [0.8600039 ]\n",
      " [0.9200456 ]\n",
      " [0.57629865]\n",
      " [0.9438544 ]\n",
      " [0.9525915 ]\n",
      " [0.9493273 ]\n",
      " [0.95696217]\n",
      " [0.7737974 ]\n",
      " [0.906905  ]\n",
      " [0.96653515]\n",
      " [0.9400393 ]\n",
      " [0.9907837 ]\n",
      " [0.9895419 ]\n",
      " [0.9163161 ]\n",
      " [0.9306163 ]\n",
      " [0.31565   ]\n",
      " [0.88586   ]\n",
      " [0.78951085]\n",
      " [0.9074574 ]\n",
      " [0.9878633 ]\n",
      " [0.94773746]\n",
      " [0.98907286]\n",
      " [0.8194335 ]\n",
      " [0.593083  ]\n",
      " [0.7898057 ]\n",
      " [0.9322829 ]\n",
      " [0.99613935]\n",
      " [0.9714674 ]\n",
      " [0.970705  ]\n",
      " [0.9292465 ]\n",
      " [0.95126677]\n",
      " [0.69736844]\n",
      " [0.9066087 ]\n",
      " [0.63486886]\n",
      " [0.92432225]\n",
      " [0.9902913 ]\n",
      " [0.94615644]\n",
      " [0.96532536]\n",
      " [0.99281985]\n",
      " [0.9599137 ]\n",
      " [0.93738306]\n",
      " [0.98506886]\n",
      " [0.97795504]\n",
      " [0.99229056]\n",
      " [0.9754616 ]\n",
      " [0.96277374]\n",
      " [0.9324507 ]\n",
      " [0.96990955]\n",
      " [0.9865978 ]\n",
      " [0.9701807 ]\n",
      " [0.94950426]\n",
      " [0.73403955]\n",
      " [0.89178884]\n",
      " [0.89188486]\n",
      " [0.97509664]\n",
      " [0.6151565 ]\n",
      " [0.9935021 ]\n",
      " [0.9782663 ]\n",
      " [0.9837087 ]\n",
      " [0.8677348 ]\n",
      " [0.92777723]\n",
      " [0.98148155]\n",
      " [0.95732325]\n",
      " [0.95215994]\n",
      " [0.9859552 ]\n",
      " [0.8281336 ]\n",
      " [0.8937355 ]\n",
      " [0.94969344]\n",
      " [0.8958438 ]\n",
      " [0.98375595]\n",
      " [0.83699983]\n",
      " [0.89743215]\n",
      " [0.9929005 ]\n",
      " [0.952694  ]\n",
      " [0.9371181 ]\n",
      " [0.88434535]\n",
      " [0.8252818 ]\n",
      " [0.9589161 ]\n",
      " [0.9576478 ]\n",
      " [0.886864  ]\n",
      " [0.97321576]\n",
      " [0.88373005]\n",
      " [0.8459288 ]\n",
      " [0.91779816]\n",
      " [0.72859794]\n",
      " [0.9717036 ]\n",
      " [0.9701436 ]\n",
      " [0.82755464]\n",
      " [0.97267175]\n",
      " [0.96608156]\n",
      " [0.9243336 ]\n",
      " [0.9771056 ]\n",
      " [0.78424466]\n",
      " [0.9569133 ]\n",
      " [0.98772395]\n",
      " [0.85685843]\n",
      " [0.9757898 ]\n",
      " [0.98727417]\n",
      " [0.8539193 ]\n",
      " [0.98399746]\n",
      " [0.99301445]\n",
      " [0.9152084 ]\n",
      " [0.9726335 ]\n",
      " [0.9285876 ]\n",
      " [0.9829911 ]\n",
      " [0.982895  ]\n",
      " [0.96820897]\n",
      " [0.6317013 ]\n",
      " [0.9873125 ]\n",
      " [0.98683083]\n",
      " [0.9690307 ]\n",
      " [0.7766627 ]\n",
      " [0.9614057 ]\n",
      " [0.9760433 ]\n",
      " [0.887324  ]\n",
      " [0.9940416 ]\n",
      " [0.9361535 ]\n",
      " [0.9209822 ]\n",
      " [0.9952768 ]\n",
      " [0.70127285]\n",
      " [0.841944  ]\n",
      " [0.9560209 ]\n",
      " [0.7092646 ]\n",
      " [0.7612901 ]\n",
      " [0.9874844 ]\n",
      " [0.9881787 ]\n",
      " [0.9861698 ]\n",
      " [0.927123  ]\n",
      " [0.9272025 ]\n",
      " [0.87773085]\n",
      " [0.98462117]\n",
      " [0.9841532 ]\n",
      " [0.99307936]\n",
      " [0.95798576]\n",
      " [0.95119977]\n",
      " [0.9399937 ]\n",
      " [0.9912238 ]\n",
      " [0.9927053 ]\n",
      " [0.9519193 ]\n",
      " [0.8147271 ]\n",
      " [0.9585721 ]\n",
      " [0.8029878 ]\n",
      " [0.8822548 ]\n",
      " [0.84446007]\n",
      " [0.8907053 ]\n",
      " [0.95596147]\n",
      " [0.944394  ]\n",
      " [0.91888475]\n",
      " [0.9536306 ]\n",
      " [0.97423446]\n",
      " [0.9425213 ]\n",
      " [0.98850775]\n",
      " [0.98824626]\n",
      " [0.97237927]\n",
      " [0.32270977]\n",
      " [0.73332655]\n",
      " [0.9612063 ]\n",
      " [0.98260653]\n",
      " [0.9499834 ]\n",
      " [0.7011347 ]\n",
      " [0.96657205]\n",
      " [0.9809409 ]\n",
      " [0.86718297]\n",
      " [0.6410252 ]\n",
      " [0.9692123 ]\n",
      " [0.98022443]\n",
      " [0.991122  ]\n",
      " [0.97881377]\n",
      " [0.99045277]\n",
      " [0.9956858 ]\n",
      " [0.9533522 ]\n",
      " [0.8890588 ]\n",
      " [0.9546885 ]\n",
      " [0.96277934]\n",
      " [0.9889619 ]\n",
      " [0.8065853 ]\n",
      " [0.9945233 ]\n",
      " [0.9872084 ]\n",
      " [0.84102815]\n",
      " [0.92482716]\n",
      " [0.9773142 ]\n",
      " [0.9201931 ]\n",
      " [0.9862223 ]\n",
      " [0.936784  ]\n",
      " [0.9801696 ]\n",
      " [0.9199897 ]\n",
      " [0.97226477]\n",
      " [0.9401205 ]\n",
      " [0.9692606 ]\n",
      " [0.9690177 ]\n",
      " [0.9585462 ]\n",
      " [0.56360614]\n",
      " [0.8813496 ]\n",
      " [0.8957503 ]\n",
      " [0.97605383]\n",
      " [0.8814308 ]\n",
      " [0.98885775]\n",
      " [0.90758306]\n",
      " [0.9286195 ]\n",
      " [0.9790613 ]\n",
      " [0.9193121 ]\n",
      " [0.9889498 ]\n",
      " [0.984153  ]\n",
      " [0.9227388 ]\n",
      " [0.99184275]\n",
      " [0.8954478 ]\n",
      " [0.9904128 ]\n",
      " [0.7953948 ]\n",
      " [0.8913668 ]\n",
      " [0.9436584 ]\n",
      " [0.96583945]\n",
      " [0.7480639 ]\n",
      " [0.98916376]\n",
      " [0.9914547 ]\n",
      " [0.9860466 ]\n",
      " [0.9915221 ]\n",
      " [0.9756021 ]\n",
      " [0.98934305]\n",
      " [0.8610902 ]\n",
      " [0.8063323 ]\n",
      " [0.9142175 ]\n",
      " [0.99794227]\n",
      " [0.85062355]\n",
      " [0.74267715]\n",
      " [0.986666  ]\n",
      " [0.9775173 ]\n",
      " [0.8461917 ]\n",
      " [0.98785156]\n",
      " [0.01941328]\n",
      " [0.98996955]\n",
      " [0.89073914]\n",
      " [0.91102886]\n",
      " [0.9493305 ]\n",
      " [0.9960083 ]\n",
      " [0.95553005]\n",
      " [0.9289292 ]\n",
      " [0.983316  ]\n",
      " [0.98118985]\n",
      " [0.7846602 ]\n",
      " [0.98088706]\n",
      " [0.978912  ]\n",
      " [0.9447697 ]\n",
      " [0.94382256]\n",
      " [0.9927868 ]\n",
      " [0.922085  ]\n",
      " [0.9848887 ]\n",
      " [0.70062906]\n",
      " [0.97976226]\n",
      " [0.9876067 ]\n",
      " [0.9019413 ]\n",
      " [0.95133793]\n",
      " [0.74522805]\n",
      " [0.92224675]\n",
      " [0.9182794 ]\n",
      " [0.93437535]\n",
      " [0.9187265 ]\n",
      " [0.97685903]\n",
      " [0.9550199 ]\n",
      " [0.9456738 ]\n",
      " [0.96863246]\n",
      " [0.9513414 ]\n",
      " [0.9728036 ]\n",
      " [0.9576134 ]\n",
      " [0.9016076 ]\n",
      " [0.99061525]\n",
      " [0.93338984]\n",
      " [0.7424068 ]\n",
      " [0.82840973]\n",
      " [0.9672482 ]\n",
      " [0.5207064 ]\n",
      " [0.990258  ]\n",
      " [0.81250894]\n",
      " [0.9781055 ]\n",
      " [0.9853543 ]\n",
      " [0.9833059 ]\n",
      " [0.9451924 ]\n",
      " [0.98484516]\n",
      " [0.9386255 ]\n",
      " [0.9702552 ]\n",
      " [0.988992  ]\n",
      " [0.93352145]\n",
      " [0.87917477]\n",
      " [0.9876659 ]\n",
      " [0.9838044 ]\n",
      " [0.9251032 ]\n",
      " [0.9521099 ]\n",
      " [0.978075  ]\n",
      " [0.9254507 ]\n",
      " [0.7831593 ]\n",
      " [0.9856278 ]\n",
      " [0.9874215 ]\n",
      " [0.94399834]\n",
      " [0.94929   ]\n",
      " [0.97894007]\n",
      " [0.9721205 ]\n",
      " [0.98125696]\n",
      " [0.99407476]\n",
      " [0.96973956]\n",
      " [0.8010293 ]\n",
      " [0.9293206 ]\n",
      " [0.97955304]\n",
      " [0.9937024 ]\n",
      " [0.9636843 ]\n",
      " [0.95778865]\n",
      " [0.8336523 ]\n",
      " [0.9766293 ]\n",
      " [0.99572253]\n",
      " [0.9969438 ]\n",
      " [0.99010044]\n",
      " [0.9230642 ]\n",
      " [0.91532856]\n",
      " [0.97830987]\n",
      " [0.7455855 ]\n",
      " [0.9361731 ]\n",
      " [0.96189284]\n",
      " [0.9689407 ]\n",
      " [0.9556192 ]\n",
      " [0.92928094]\n",
      " [0.9766698 ]\n",
      " [0.76235634]\n",
      " [0.8094169 ]\n",
      " [0.8819403 ]\n",
      " [0.96506673]\n",
      " [0.88002574]\n",
      " [0.9731488 ]\n",
      " [0.98682076]\n",
      " [0.74659956]\n",
      " [0.7251537 ]\n",
      " [0.9787056 ]\n",
      " [0.9518991 ]\n",
      " [0.81824106]\n",
      " [0.993451  ]\n",
      " [0.97820616]\n",
      " [0.96158195]\n",
      " [0.9911288 ]\n",
      " [0.9883703 ]\n",
      " [0.97034913]\n",
      " [0.98499286]\n",
      " [0.9554652 ]\n",
      " [0.890405  ]\n",
      " [0.917784  ]\n",
      " [0.95557255]\n",
      " [0.7038512 ]\n",
      " [0.9823866 ]\n",
      " [0.98038006]\n",
      " [0.8826129 ]\n",
      " [0.98966986]\n",
      " [0.98359317]\n",
      " [0.9852787 ]\n",
      " [0.956683  ]\n",
      " [0.94483054]\n",
      " [0.984041  ]\n",
      " [0.97420645]\n",
      " [0.9798606 ]\n",
      " [0.9913551 ]\n",
      " [0.93557954]\n",
      " [0.9820326 ]\n",
      " [0.9787829 ]\n",
      " [0.9251121 ]\n",
      " [0.90690213]\n",
      " [0.7204285 ]\n",
      " [0.76567864]\n",
      " [0.9855753 ]\n",
      " [0.954439  ]\n",
      " [0.92835206]\n",
      " [0.9451507 ]\n",
      " [0.99660563]\n",
      " [0.91754156]\n",
      " [0.9726812 ]\n",
      " [0.8300443 ]\n",
      " [0.9734485 ]\n",
      " [0.6072441 ]\n",
      " [0.9572535 ]\n",
      " [0.9471869 ]\n",
      " [0.95578015]\n",
      " [0.8851923 ]\n",
      " [0.7716757 ]\n",
      " [0.93513876]\n",
      " [0.9971552 ]\n",
      " [0.9563507 ]\n",
      " [0.9959676 ]\n",
      " [0.9878165 ]\n",
      " [0.97991395]\n",
      " [0.98892605]\n",
      " [0.87257594]\n",
      " [0.94446653]\n",
      " [0.9841787 ]\n",
      " [0.71045405]\n",
      " [0.99374676]\n",
      " [0.7925633 ]\n",
      " [0.99579763]\n",
      " [0.9894237 ]\n",
      " [0.9544029 ]\n",
      " [0.6787513 ]\n",
      " [0.9196602 ]\n",
      " [0.8340879 ]\n",
      " [0.98106766]\n",
      " [0.9351904 ]\n",
      " [0.99704957]\n",
      " [0.84621584]\n",
      " [0.935267  ]\n",
      " [0.9590859 ]\n",
      " [0.9472087 ]\n",
      " [0.34545222]\n",
      " [0.9401123 ]\n",
      " [0.98785245]\n",
      " [0.9385369 ]\n",
      " [0.9540628 ]\n",
      " [0.887068  ]\n",
      " [0.95034724]\n",
      " [0.99476916]\n",
      " [0.9196802 ]\n",
      " [0.91563445]\n",
      " [0.9828538 ]\n",
      " [0.9894488 ]\n",
      " [0.95753044]\n",
      " [0.82095975]\n",
      " [0.9766782 ]\n",
      " [0.9798759 ]\n",
      " [0.86188084]\n",
      " [0.996278  ]\n",
      " [0.91976637]\n",
      " [0.94683826]\n",
      " [0.93917584]\n",
      " [0.97213507]\n",
      " [0.97037673]\n",
      " [0.9621525 ]\n",
      " [0.981043  ]\n",
      " [0.8149155 ]\n",
      " [0.8717594 ]\n",
      " [0.9785216 ]\n",
      " [0.99531484]\n",
      " [0.98501796]\n",
      " [0.94537777]\n",
      " [0.98002213]\n",
      " [0.9881997 ]\n",
      " [0.9784241 ]\n",
      " [0.9928474 ]\n",
      " [0.87673503]\n",
      " [0.91451883]\n",
      " [0.8568452 ]\n",
      " [0.5922419 ]\n",
      " [0.73856694]\n",
      " [0.7104865 ]\n",
      " [0.9702895 ]\n",
      " [0.97208303]\n",
      " [0.98137385]\n",
      " [0.96585566]\n",
      " [0.9721549 ]\n",
      " [0.9120816 ]\n",
      " [0.91080284]\n",
      " [0.9962459 ]\n",
      " [0.93017507]\n",
      " [0.686504  ]\n",
      " [0.9188364 ]\n",
      " [0.84863365]\n",
      " [0.8893968 ]\n",
      " [0.9403821 ]\n",
      " [0.9770732 ]\n",
      " [0.9911011 ]\n",
      " [0.9955621 ]\n",
      " [0.7181751 ]\n",
      " [0.8917694 ]\n",
      " [0.92360455]\n",
      " [0.9152118 ]\n",
      " [0.9647633 ]\n",
      " [0.9752914 ]\n",
      " [0.9961183 ]\n",
      " [0.9673497 ]\n",
      " [0.9290686 ]\n",
      " [0.87621605]\n",
      " [0.42290702]\n",
      " [0.92637736]\n",
      " [0.88031465]\n",
      " [0.9913509 ]\n",
      " [0.9556719 ]\n",
      " [0.96761864]\n",
      " [0.9581211 ]\n",
      " [0.95232695]\n",
      " [0.8379886 ]\n",
      " [0.96720964]\n",
      " [0.9566362 ]\n",
      " [0.919312  ]\n",
      " [0.968904  ]\n",
      " [0.98575854]\n",
      " [0.96505153]\n",
      " [0.90663916]\n",
      " [0.9907285 ]\n",
      " [0.85519755]\n",
      " [0.9700917 ]\n",
      " [0.9798952 ]\n",
      " [0.958805  ]\n",
      " [0.8654009 ]\n",
      " [0.97156984]\n",
      " [0.9815439 ]\n",
      " [0.8367304 ]\n",
      " [0.81692475]\n",
      " [0.9709419 ]\n",
      " [0.9757908 ]\n",
      " [0.9776053 ]\n",
      " [0.98740923]\n",
      " [0.9844698 ]\n",
      " [0.9815376 ]\n",
      " [0.9488355 ]\n",
      " [0.97291666]\n",
      " [0.96159965]\n",
      " [0.97116405]\n",
      " [0.8836869 ]\n",
      " [0.9366375 ]\n",
      " [0.99005055]\n",
      " [0.9776064 ]\n",
      " [0.9016211 ]\n",
      " [0.79686743]\n",
      " [0.98784095]\n",
      " [0.98183227]\n",
      " [0.98318416]\n",
      " [0.92262906]\n",
      " [0.9728062 ]\n",
      " [0.9902136 ]\n",
      " [0.9766184 ]\n",
      " [0.6873107 ]\n",
      " [0.9906784 ]\n",
      " [0.99367964]\n",
      " [0.7121882 ]\n",
      " [0.29516178]\n",
      " [0.871057  ]\n",
      " [0.89320385]\n",
      " [0.91700774]\n",
      " [0.93760335]\n",
      " [0.95897937]\n",
      " [0.8261759 ]\n",
      " [0.9666659 ]\n",
      " [0.991495  ]\n",
      " [0.68073213]\n",
      " [0.8965276 ]\n",
      " [0.89057046]\n",
      " [0.89393353]\n",
      " [0.9126461 ]\n",
      " [0.97546774]\n",
      " [0.83215076]\n",
      " [0.9833521 ]\n",
      " [0.7883915 ]\n",
      " [0.97287965]\n",
      " [0.9328004 ]\n",
      " [0.9784904 ]\n",
      " [0.979045  ]\n",
      " [0.98385566]\n",
      " [0.9903329 ]] \n",
      "cost:  -0.009163522 \n",
      "accuracy:  0.6587615\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    feed = {X: x_data, Y: y_data}\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = feed)\n",
    "        if step % 400 == 0:\n",
    "            print(step, sess.run(cost, feed_dict = feed))\n",
    "            \n",
    "    \n",
    "    h, c, a = sess.run([hypothesis, cost, accuracy], feed_dict = feed)\n",
    "    print(\"\\nhypothesis: \", h, \"\\ncost: \", c, \"\\naccuracy: \", a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
